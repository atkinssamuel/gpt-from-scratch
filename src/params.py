params = {
    # training
    "n_updates": 1000,
    "checkpoint_iter": 10,
    "n_eval_iters": 10,
    "learning_rate": 3e-4,
    # model
    "block_size": 256,
    "batch_size": 64,
    "n_embd": 384,
    "n_heads": 6,
    "n_layers": 6,
    "model_name": "optimal.model",
    # "model_name": None,
}
